/**
 * ğŸŸ¢ TDD ç»¿é˜¶æ®µï¼šæµå¼èŠå¤©åŠŸèƒ½å®ç°
 * å®ç°æµå¼è¾“å‡ºå’Œå®æ—¶èŠå¤©åŠŸèƒ½
 */

import { MCPOpenAIClient } from './mcp-openai';
import { MCPServer } from './mcp-server';
import { OpenAI } from 'openai';

/**
 * èŠå¤©ç»“æœæ¥å£
 */
export interface ChatResult {
  content: string;
  tokens: number;
  toolCalls?: ToolCallInfo[];
}

/**
 * å·¥å…·è°ƒç”¨ä¿¡æ¯æ¥å£
 */
export interface ToolCallInfo {
  name: string;
  arguments: any;
  result: any;
}

/**
 * ç»Ÿè®¡ä¿¡æ¯æ¥å£
 */
export interface ChatStats {
  totalMessages: number;
  totalTokens: number;
  totalToolCalls: number;
}

/**
 * æµå¼èŠå¤©ç±»
 */
export class StreamChat {
  private openaiClient: MCPOpenAIClient;
  private mcpServer: MCPServer;
  private conversationHistory: OpenAI.Chat.Completions.ChatCompletionMessageParam[] = [];
  private realTimeOutput: boolean = true;
  private stats: ChatStats = {
    totalMessages: 0,
    totalTokens: 0,
    totalToolCalls: 0
  };

  constructor(openaiClient: MCPOpenAIClient, mcpServer: MCPServer) {
    this.openaiClient = openaiClient;
    this.mcpServer = mcpServer;
  }

  /**
   * è·å– OpenAI å®¢æˆ·ç«¯
   */
  getOpenAIClient(): MCPOpenAIClient {
    return this.openaiClient;
  }

  /**
   * è·å– MCP æœåŠ¡å™¨
   */
  getMCPServer(): MCPServer {
    return this.mcpServer;
  }

  /**
   * åŸºç¡€æµå¼èŠå¤©
   */
  async chat(message: string): Promise<ChatResult> {
    const userMessage: OpenAI.Chat.Completions.ChatCompletionMessageParam = {
      role: 'user',
      content: message
    };

    // æ·»åŠ åˆ°å¯¹è¯å†å²
    this.conversationHistory.push(userMessage);
    this.stats.totalMessages++;

    try {
      const stream = await this.openaiClient.chatCompletionStream([...this.conversationHistory]);
      
      let fullContent = '';
      let tokenCount = 0;

      for await (const chunk of stream) {
        const content = chunk.choices[0]?.delta?.content;
        if (content) {
          fullContent += content;
          tokenCount++;
          
          // å®æ—¶è¾“å‡º
          if (this.realTimeOutput) {
            process.stdout.write(content);
          }
        }
      }

      // æ·»åŠ åŠ©æ‰‹å“åº”åˆ°å¯¹è¯å†å²
      const assistantMessage: OpenAI.Chat.Completions.ChatCompletionMessageParam = {
        role: 'assistant',
        content: fullContent
      };
      this.conversationHistory.push(assistantMessage);
      this.stats.totalMessages++;
      this.stats.totalTokens += tokenCount;

      return {
        content: fullContent,
        tokens: tokenCount
      };
    } catch (error) {
      throw error;
    }
  }

  /**
   * å¸¦å·¥å…·è°ƒç”¨çš„æµå¼èŠå¤©
   */
  async chatWithTools(message: string): Promise<ChatResult> {
    const userMessage: OpenAI.Chat.Completions.ChatCompletionMessageParam = {
      role: 'user',
      content: message
    };

    // æ·»åŠ åˆ°å¯¹è¯å†å²
    this.conversationHistory.push(userMessage);
    this.stats.totalMessages++;

    try {
      // é¦–å…ˆè¿›è¡Œå¸¦å·¥å…·è°ƒç”¨çš„èŠå¤©å®Œæˆ
      const response = await this.openaiClient.chatCompletionWithTools([...this.conversationHistory]);
      const assistantMessage = response.choices[0]?.message;

      if (!assistantMessage) {
        throw new Error('æ²¡æœ‰æ”¶åˆ°åŠ©æ‰‹å“åº”');
      }

      // æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å¯¹è¯å†å²
      this.conversationHistory.push(assistantMessage);
      this.stats.totalMessages++;

      const toolCalls: ToolCallInfo[] = [];

      // å¤„ç†å·¥å…·è°ƒç”¨
      if (assistantMessage.tool_calls && assistantMessage.tool_calls.length > 0) {
        for (const toolCall of assistantMessage.tool_calls) {
          const toolResult = await this.openaiClient.executeToolCall(toolCall);
          this.conversationHistory.push(toolResult);
          this.stats.totalToolCalls++;

          if (toolCall.type === 'function') {
            toolCalls.push({
              name: toolCall.function.name,
              arguments: JSON.parse(toolCall.function.arguments),
              result: JSON.parse(toolResult.content)
            });
          }
        }

        // è·å–æœ€ç»ˆçš„æµå¼å“åº”
        const finalStream = await this.openaiClient.chatCompletionStream([...this.conversationHistory]);
        
        let finalContent = '';
        let tokenCount = 0;

        for await (const chunk of finalStream) {
          const content = chunk.choices[0]?.delta?.content;
          if (content) {
            finalContent += content;
            tokenCount++;
            
            if (this.realTimeOutput) {
              process.stdout.write(content);
            }
          }
        }

        // æ·»åŠ æœ€ç»ˆå“åº”åˆ°å¯¹è¯å†å²
        const finalMessage: OpenAI.Chat.Completions.ChatCompletionMessageParam = {
          role: 'assistant',
          content: finalContent
        };
        this.conversationHistory.push(finalMessage);
        this.stats.totalMessages++;
        this.stats.totalTokens += tokenCount;

        return {
          content: finalContent,
          tokens: tokenCount,
          toolCalls
        };
      } else {
        // æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿”å›åŠ©æ‰‹æ¶ˆæ¯
        const content = assistantMessage.content || '';
        this.stats.totalTokens += content.length;

        return {
          content,
          tokens: content.length,
          toolCalls
        };
      }
    } catch (error) {
      throw error;
    }
  }

  /**
   * è·å–å¯¹è¯å†å²
   */
  getConversationHistory(): OpenAI.Chat.Completions.ChatCompletionMessageParam[] {
    return [...this.conversationHistory];
  }

  /**
   * æ¸…é™¤å¯¹è¯å†å²
   */
  clearHistory(): void {
    this.conversationHistory = [];
  }

  /**
   * è®¾ç½®å®æ—¶è¾“å‡º
   */
  setRealTimeOutput(enabled: boolean): void {
    this.realTimeOutput = enabled;
  }

  /**
   * è·å–ç»Ÿè®¡ä¿¡æ¯
   */
  getStats(): ChatStats {
    return { ...this.stats };
  }

  /**
   * é‡ç½®ç»Ÿè®¡ä¿¡æ¯
   */
  resetStats(): void {
    this.stats = {
      totalMessages: 0,
      totalTokens: 0,
      totalToolCalls: 0
    };
  }
}
