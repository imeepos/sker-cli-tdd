/**
 * üî¥ TDD Á∫¢Èò∂ÊÆµÔºöMCP OpenAI ÈõÜÊàêÂäüËÉΩÊµãËØï
 * Ëøô‰∫õÊµãËØïÊúÄÂàù‰ºöÂ§±Ë¥• - ËøôÊòØÊ≠£Á°ÆÁöÑ TDD Ë°å‰∏∫ÔºÅ
 */

import { MCPServer } from './mcp-server';
import { MCPOpenAIClient, MCPOpenAIConfig } from './mcp-openai'; // ‚ùå Ëøô‰ºöÂ§±Ë¥• - Ê≠£Á°ÆÁöÑÔºÅ
import { MCPWorkspaceManager } from './mcp-workspace';
import { MCPPromptManager } from './mcp-prompts';

// Mock OpenAI SDK
const mockCreate = jest.fn();
jest.mock('openai', () => {
  return {
    OpenAI: jest.fn().mockImplementation(() => ({
      chat: {
        completions: {
          create: mockCreate
        }
      }
    }))
  };
});

describe('MCP OpenAI ÈõÜÊàêÂäüËÉΩ', () => {
  describe('OpenAI ÂÆ¢Êà∑Á´ØÈÖçÁΩÆ', () => {
    it('Â∫îËØ•ÂÆö‰πâ MCPOpenAIConfig Êé•Âè£', () => {
      const config: MCPOpenAIConfig = { // ‚ùå ‰ºöÂ§±Ë¥• - Êé•Âè£‰∏çÂ≠òÂú®
        apiKey: 'test-api-key',
        model: 'gpt-4',
        baseURL: 'https://api.openai.com/v1',
        maxTokens: 1000,
        temperature: 0.7
      };
      
      expect(config.apiKey).toBe('test-api-key');
      expect(config.model).toBe('gpt-4');
      expect(config.maxTokens).toBe(1000);
    });

    it('Â∫îËØ•ÊîØÊåÅ‰ªéÁéØÂ¢ÉÂèòÈáèÂä†ËΩΩÈÖçÁΩÆ', () => {
      // Ê®°ÊãüÁéØÂ¢ÉÂèòÈáè
      process.env['OPENAI_API_KEY'] = 'env-api-key';
      process.env['OPENAI_MODEL'] = 'gpt-3.5-turbo';
      process.env['OPENAI_BASE_URL'] = 'https://custom.openai.com/v1';

      const config = MCPOpenAIClient.loadConfigFromEnv();
      expect(config.apiKey).toBe('env-api-key');
      expect(config.model).toBe('gpt-3.5-turbo');
      expect(config.baseURL).toBe('https://custom.openai.com/v1');

      // Ê∏ÖÁêÜÁéØÂ¢ÉÂèòÈáè
      delete process.env['OPENAI_API_KEY'];
      delete process.env['OPENAI_MODEL'];
      delete process.env['OPENAI_BASE_URL'];
    });
  });

  describe('OpenAI ÂÆ¢Êà∑Á´Ø', () => {
    let openaiClient: MCPOpenAIClient;
    let mcpServer: MCPServer;

    beforeEach(() => {
      mcpServer = new MCPServer();
      const config: MCPOpenAIConfig = {
        apiKey: 'test-api-key',
        model: 'gpt-4',
        maxTokens: 1000,
        temperature: 0.7
      };
      openaiClient = new MCPOpenAIClient(config, mcpServer); // ‚ùå ‰ºöÂ§±Ë¥• - Á±ª‰∏çÂ≠òÂú®
    });

    it('Â∫îËØ•ÂàõÂª∫ OpenAI ÂÆ¢Êà∑Á´ØÂÆû‰æã', () => {
      expect(openaiClient).toBeInstanceOf(MCPOpenAIClient);
    });

    it('Â∫îËØ•Ëé∑ÂèñÈÖçÁΩÆ‰ø°ÊÅØ', () => {
      const config = openaiClient.getConfig(); // ‚ùå ‰ºöÂ§±Ë¥•
      expect(config.apiKey).toBe('test-api-key');
      expect(config.model).toBe('gpt-4');
    });

    it('Â∫îËØ•ËÆæÁΩÆ MCP ÊúçÂä°Âô®', () => {
      const newServer = new MCPServer();
      openaiClient.setMCPServer(newServer); // ‚ùå ‰ºöÂ§±Ë¥•
      expect(openaiClient.getMCPServer()).toBe(newServer);
    });
  });

  describe('Â∑•ÂÖ∑Ë∞ÉÁî®ÈõÜÊàê', () => {
    let openaiClient: MCPOpenAIClient;
    let mcpServer: MCPServer;
    let workspaceManager: MCPWorkspaceManager;

    beforeEach(() => {
      mcpServer = new MCPServer();
      workspaceManager = new MCPWorkspaceManager();
      mcpServer.setWorkspaceManager(workspaceManager);
      
      // Ê≥®ÂÜåÊµãËØïÂ∑•ÂÖ∑
      mcpServer.registerTool({
        name: 'add',
        description: '‰∏§Êï∞Áõ∏Âä†',
        schema: {
          type: 'object',
          properties: {
            a: { type: 'number', description: 'Á¨¨‰∏Ä‰∏™Êï∞' },
            b: { type: 'number', description: 'Á¨¨‰∫å‰∏™Êï∞' }
          },
          required: ['a', 'b']
        },
        handler: async (params) => ({ result: params.a + params.b })
      });

      const config: MCPOpenAIConfig = {
        apiKey: 'test-api-key',
        model: 'gpt-4'
      };
      openaiClient = new MCPOpenAIClient(config, mcpServer);
    });

    it('Â∫îËØ•Â∞Ü MCP Â∑•ÂÖ∑ËΩ¨Êç¢‰∏∫ OpenAI ÂáΩÊï∞Ê†ºÂºè', () => {
      const openaiTools = openaiClient.getOpenAITools(); // ‚ùå ‰ºöÂ§±Ë¥•
      expect(openaiTools).toHaveLength(1);
      expect(openaiTools[0]).toEqual({
        type: 'function',
        function: {
          name: 'add',
          description: '‰∏§Êï∞Áõ∏Âä†',
          parameters: {
            type: 'object',
            properties: {
              a: { type: 'number', description: 'Á¨¨‰∏Ä‰∏™Êï∞' },
              b: { type: 'number', description: 'Á¨¨‰∫å‰∏™Êï∞' }
            },
            required: ['a', 'b']
          }
        }
      });
    });

    it('Â∫îËØ•ÊâßË°åÂ∑•ÂÖ∑Ë∞ÉÁî®', async () => {
      const toolCall = {
        id: 'call_123',
        type: 'function' as const,
        function: {
          name: 'add',
          arguments: '{"a": 5, "b": 3}'
        }
      };

      const result = await openaiClient.executeToolCall(toolCall); // ‚ùå ‰ºöÂ§±Ë¥•
      expect(result).toEqual({
        tool_call_id: 'call_123',
        role: 'tool',
        content: JSON.stringify({ result: 8 })
      });
    });

    it('Â∫îËØ•Â§ÑÁêÜÂ∑•ÂÖ∑Ë∞ÉÁî®ÈîôËØØ', async () => {
      const toolCall = {
        id: 'call_456',
        type: 'function' as const,
        function: {
          name: 'nonexistent',
          arguments: '{}'
        }
      };

      const result = await openaiClient.executeToolCall(toolCall);
      expect(result.tool_call_id).toBe('call_456');
      expect(result.role).toBe('tool');
      expect(JSON.parse(result.content)).toEqual({
        error: 'Â∑•ÂÖ∑ "nonexistent" Êú™ÊâæÂà∞'
      });
    });
  });

  describe('ËÅäÂ§©ÂÆåÊàêÈõÜÊàê', () => {
    let openaiClient: MCPOpenAIClient;
    let mcpServer: MCPServer;

    beforeEach(() => {
      mcpServer = new MCPServer();
      const config: MCPOpenAIConfig = {
        apiKey: 'test-api-key',
        model: 'gpt-4'
      };
      openaiClient = new MCPOpenAIClient(config, mcpServer);

      // Mock OpenAI ÂìçÂ∫î
      mockCreate.mockResolvedValue({
        choices: [{
          message: {
            role: 'assistant',
            content: '‰Ω†Â•ΩÔºÅÊàëÂèØ‰ª•Â∏ÆÂä©‰Ω†ËøõË°åËÆ°ÁÆó„ÄÇ',
            tool_calls: null
          }
        }],
        usage: {
          prompt_tokens: 10,
          completion_tokens: 15,
          total_tokens: 25
        }
      });
    });

    it('Â∫îËØ•ÂèëÈÄÅËÅäÂ§©ÂÆåÊàêËØ∑Ê±Ç', async () => {
      const messages = [
        { role: 'user' as const, content: '‰Ω†Â•Ω' }
      ];

      const response = await openaiClient.chatCompletion(messages);
      expect(response.choices[0]?.message?.content).toBe('‰Ω†Â•ΩÔºÅÊàëÂèØ‰ª•Â∏ÆÂä©‰Ω†ËøõË°åËÆ°ÁÆó„ÄÇ');
    });

    it('Â∫îËØ•ÊîØÊåÅÂ∑•ÂÖ∑Ë∞ÉÁî®ÁöÑËÅäÂ§©ÂÆåÊàê', async () => {
      // Mock Â∏¶Â∑•ÂÖ∑Ë∞ÉÁî®ÁöÑÂìçÂ∫î
      mockCreate.mockResolvedValue({
        choices: [{
          message: {
            role: 'assistant',
            content: null,
            tool_calls: [{
              id: 'call_123',
              type: 'function',
              function: {
                name: 'add',
                arguments: '{"a": 5, "b": 3}'
              }
            }]
          }
        }]
      });

      const messages = [
        { role: 'user' as const, content: 'ËÆ°ÁÆó 5 + 3' }
      ];

      const response = await openaiClient.chatCompletionWithTools(messages);
      expect(response.choices[0]?.message?.tool_calls).toHaveLength(1);
      const toolCall = response.choices[0]?.message?.tool_calls?.[0];
      expect(toolCall?.type).toBe('function');
      if (toolCall?.type === 'function') {
        expect(toolCall.function.name).toBe('add');
      }
    });
  });

  describe('ÊèêÁ§∫ËØçÈõÜÊàê', () => {
    let openaiClient: MCPOpenAIClient;
    let mcpServer: MCPServer;
    let promptManager: MCPPromptManager;

    beforeEach(() => {
      mcpServer = new MCPServer();
      promptManager = new MCPPromptManager();
      mcpServer.setPromptManager(promptManager);

      // Ê≥®ÂÜåÊµãËØïÊèêÁ§∫ËØç
      promptManager.registerPrompt({
        name: 'greeting',
        description: 'ÈóÆÂÄôÊèêÁ§∫ËØç',
        template: '‰Ω†Â•ΩÔºå{{name}}ÔºÅÊàëÊòØ {{role}}ÔºåÂèØ‰ª•Â∏ÆÂä©‰Ω† {{task}}„ÄÇ',
        arguments: [
          { name: 'name', description: 'Áî®Êà∑ÂêçÁß∞', required: true },
          { name: 'role', description: 'ËßíËâ≤', required: false, default: 'AIÂä©Êâã' },
          { name: 'task', description: '‰ªªÂä°', required: false, default: 'Ëß£ÂÜ≥ÈóÆÈ¢ò' }
        ]
      });

      const config: MCPOpenAIConfig = {
        apiKey: 'test-api-key',
        model: 'gpt-4'
      };
      openaiClient = new MCPOpenAIClient(config, mcpServer);
    });

    it('Â∫îËØ•‰ΩøÁî®ÊèêÁ§∫ËØçËøõË°åËÅäÂ§©ÂÆåÊàê', async () => {
      mockCreate.mockResolvedValue({
        choices: [{
          message: {
            role: 'assistant',
            content: '‰Ω†Â•ΩÔºåÂº†‰∏âÔºÅÊàëÊòØ AIÂä©ÊâãÔºåÂèØ‰ª•Â∏ÆÂä©‰Ω†Ëß£ÂÜ≥ÈóÆÈ¢ò„ÄÇ'
          }
        }]
      });

      const response = await openaiClient.chatCompletionWithPrompt(
        'greeting',
        { name: 'Âº†‰∏â' },
        [{ role: 'user', content: 'ËØ∑‰ªãÁªç‰∏Ä‰∏ãËá™Â∑±' }]
      );

      expect(response.choices[0]?.message?.content).toContain('Âº†‰∏â');
      expect(response.choices[0]?.message?.content).toContain('AIÂä©Êâã');
    });

    it('Â∫îËØ•Â§ÑÁêÜÊèêÁ§∫ËØçÊ∏≤ÊüìÈîôËØØ', async () => {
      await expect(openaiClient.chatCompletionWithPrompt(
        'nonexistent',
        {},
        [{ role: 'user', content: 'ÊµãËØï' }]
      )).rejects.toThrow('Prompt "nonexistent" ‰∏çÂ≠òÂú®');
    });
  });

  describe('ÊµÅÂºèÂìçÂ∫î', () => {
    let openaiClient: MCPOpenAIClient;
    let mcpServer: MCPServer;

    beforeEach(() => {
      mcpServer = new MCPServer();
      const config: MCPOpenAIConfig = {
        apiKey: 'test-api-key',
        model: 'gpt-4'
      };
      openaiClient = new MCPOpenAIClient(config, mcpServer);
    });

    it('Â∫îËØ•ÊîØÊåÅÊµÅÂºèËÅäÂ§©ÂÆåÊàê', async () => {
      // Mock ÊµÅÂºèÂìçÂ∫î
      const mockCreate = require('openai').OpenAI().chat.completions.create;
      const mockStream = {
        [Symbol.asyncIterator]: async function* () {
          yield { choices: [{ delta: { content: '‰Ω†Â•Ω' } }] };
          yield { choices: [{ delta: { content: 'ÔºÅ' } }] };
        }
      };
      mockCreate.mockResolvedValue(mockStream);

      const messages = [
        { role: 'user' as const, content: '‰Ω†Â•Ω' }
      ];

      const stream = await openaiClient.chatCompletionStream(messages);
      const chunks: any[] = [];
      for await (const chunk of stream) {
        chunks.push(chunk);
      }

      expect(chunks).toHaveLength(2);
      expect(chunks[0]?.choices?.[0]?.delta?.content).toBe('‰Ω†Â•Ω');
      expect(chunks[1]?.choices?.[0]?.delta?.content).toBe('ÔºÅ');
    });
  });
});
