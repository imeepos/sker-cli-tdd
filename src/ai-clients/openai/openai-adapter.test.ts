/**
 * ğŸ§ª OpenAIé€‚é…å™¨æµ‹è¯•å¥—ä»¶
 * éµå¾ªTDDåŸåˆ™ï¼Œæµ‹è¯•OpenAIAdapterç±»çš„æ‰€æœ‰åŠŸèƒ½
 */

import { OpenAIAdapter } from './openai-adapter';
import { UnifiedAIConfig, UnifiedChunk, UnifiedMessage, UnifiedTool } from '../base/unified-types';
import OpenAI from 'openai';

// Mock OpenAIæ¨¡å—
jest.mock('openai');
const MockedOpenAI = OpenAI as jest.MockedClass<typeof OpenAI>;

describe('OpenAIAdapter', () => {
  let adapter: OpenAIAdapter;
  let mockConfig: UnifiedAIConfig;
  let mockOpenAIClient: jest.Mocked<OpenAI>;
  let consoleSpy: jest.SpyInstance;

  beforeEach(() => {
    // é‡ç½®æ‰€æœ‰mock
    jest.clearAllMocks();

    // Mock console.log to prevent Jest from capturing unexpected output
    consoleSpy = jest.spyOn(console, 'log').mockImplementation();

    // åˆ›å»ºmocké…ç½®
    mockConfig = {
      provider: 'openai',
      apiKey: 'test-api-key',
      model: 'gpt-3.5-turbo',
      baseURL: 'https://api.openai.com/v1',
      maxTokens: 1000,
      temperature: 0.7,
      timeout: 30000,
    };

    // åˆ›å»ºmock OpenAIå®¢æˆ·ç«¯
    mockOpenAIClient = {
      chat: {
        completions: {
          create: jest.fn(),
        },
      },
    } as any;

    // ç¡®ä¿createæ–¹æ³•æ˜¯jest mockå‡½æ•°
    (mockOpenAIClient.chat.completions.create as jest.Mock) = jest.fn();

    // è®¾ç½®OpenAIæ„é€ å‡½æ•°mock
    MockedOpenAI.mockImplementation(() => mockOpenAIClient);

    // åˆ›å»ºé€‚é…å™¨å®ä¾‹
    adapter = new OpenAIAdapter(mockConfig);
  });

  afterEach(() => {
    // Restore console.log
    if (consoleSpy) {
      consoleSpy.mockRestore();
    }
  });

  describe('æ„é€ å‡½æ•°', () => {
    it('åº”è¯¥æ­£ç¡®åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯', () => {
      expect(MockedOpenAI).toHaveBeenCalledWith({
        apiKey: 'test-api-key',
        baseURL: 'https://api.openai.com/v1',
        timeout: 30000,
      });
      expect(adapter.provider).toBe('openai');
      expect(adapter.config).toEqual(mockConfig);
    });

    it('åº”è¯¥ä½¿ç”¨é»˜è®¤è¶…æ—¶æ—¶é—´', () => {
      const configWithoutTimeout = { ...mockConfig };
      delete configWithoutTimeout.timeout;
      
      new OpenAIAdapter(configWithoutTimeout);
      
      expect(MockedOpenAI).toHaveBeenCalledWith({
        apiKey: 'test-api-key',
        baseURL: 'https://api.openai.com/v1',
        timeout: 30000,
      });
    });
  });

  describe('chatCompletion', () => {
    it('åº”è¯¥æˆåŠŸå®ŒæˆèŠå¤©å¯¹è¯', async () => {
      const mockResponse = {
        id: 'chatcmpl-123',
        object: 'chat.completion',
        created: 1677652288,
        model: 'gpt-3.5-turbo',
        choices: [{
          index: 0,
          message: {
            role: 'assistant',
            content: 'ä½ å¥½ï¼æˆ‘æ˜¯AIåŠ©æ‰‹ã€‚',
          },
          finish_reason: 'stop',
        }],
        usage: {
          prompt_tokens: 10,
          completion_tokens: 20,
          total_tokens: 30,
        },
      };

      (mockOpenAIClient.chat.completions.create as jest.Mock).mockResolvedValue(mockResponse as any);

      const messages: UnifiedMessage[] = [
        { role: 'user', content: 'ä½ å¥½' },
      ];

      const result = await adapter.chatCompletion({ messages });

      expect(mockOpenAIClient.chat.completions.create).toHaveBeenCalledWith({
        model: 'gpt-3.5-turbo',
        messages: [{ role: 'user', content: 'ä½ å¥½' }],
        max_tokens: 1000,
        temperature: 0.7,
        tools: undefined,
        tool_choice: undefined,
        stream: false,
      });

      expect(result.choices[0]?.message?.content).toBe('ä½ å¥½ï¼æˆ‘æ˜¯AIåŠ©æ‰‹ã€‚');
      expect(result.usage?.totalTokens).toBe(30);
    });

    it('åº”è¯¥å¤„ç†å¸¦å·¥å…·çš„èŠå¤©å¯¹è¯', async () => {
      const mockResponse = {
        id: 'chatcmpl-123',
        object: 'chat.completion',
        created: 1677652288,
        model: 'gpt-3.5-turbo',
        choices: [{
          index: 0,
          message: {
            role: 'assistant',
            content: null,
            tool_calls: [{
              id: 'call_123',
              type: 'function',
              function: {
                name: 'get_weather',
                arguments: '{"location": "åŒ—äº¬"}',
              },
            }],
          },
          finish_reason: 'tool_calls',
        }],
      };

      (mockOpenAIClient.chat.completions.create as jest.Mock).mockResolvedValue(mockResponse as any);

      const messages: UnifiedMessage[] = [
        { role: 'user', content: 'åŒ—äº¬å¤©æ°”å¦‚ä½•ï¼Ÿ' },
      ];

      const tools: UnifiedTool[] = [{
        type: 'function',
        function: {
          name: 'get_weather',
          description: 'è·å–å¤©æ°”ä¿¡æ¯',
          parameters: {
            type: 'object',
            properties: {
              location: { type: 'string', description: 'åŸå¸‚åç§°' },
            },
            required: ['location'],
          },
        },
      }];

      const result = await adapter.chatCompletion({ messages, tools, toolChoice: 'auto' });

      expect(mockOpenAIClient.chat.completions.create).toHaveBeenCalledWith({
        model: 'gpt-3.5-turbo',
        messages: [{ role: 'user', content: 'åŒ—äº¬å¤©æ°”å¦‚ä½•ï¼Ÿ' }],
        max_tokens: 1000,
        temperature: 0.7,
        tools: [{
          type: 'function',
          function: {
            name: 'get_weather',
            description: 'è·å–å¤©æ°”ä¿¡æ¯',
            parameters: {
              type: 'object',
              properties: {
                location: { type: 'string', description: 'åŸå¸‚åç§°' },
              },
              required: ['location'],
            },
          },
        }],
        tool_choice: 'auto',
        stream: false,
      });

      expect(result.choices[0]?.message?.toolCalls?.[0]?.function.name).toBe('get_weather');
    });

    it('åº”è¯¥å¤„ç†APIé”™è¯¯', async () => {
      (mockOpenAIClient.chat.completions.create as jest.Mock).mockRejectedValue(new Error('API é”™è¯¯'));

      const messages: UnifiedMessage[] = [
        { role: 'user', content: 'æµ‹è¯•' },
      ];

      await expect(adapter.chatCompletion({ messages })).rejects.toThrow('API é”™è¯¯');
    });
  });

  describe('chatCompletionStream', () => {
    it('åº”è¯¥æˆåŠŸå¤„ç†æµå¼å“åº”', async () => {
      const mockChunks = [
        {
          id: 'chatcmpl-123',
          object: 'chat.completion.chunk',
          created: 1677652288,
          model: 'gpt-3.5-turbo',
          choices: [{
            index: 0,
            delta: { role: 'assistant', content: 'ä½ å¥½' },
            finish_reason: null,
          }],
        },
        {
          id: 'chatcmpl-123',
          object: 'chat.completion.chunk',
          created: 1677652288,
          model: 'gpt-3.5-turbo',
          choices: [{
            index: 0,
            delta: { content: 'ï¼' },
            finish_reason: 'stop',
          }],
        },
      ];

      const mockStream = {
        async *[Symbol.asyncIterator]() {
          for (const chunk of mockChunks) {
            yield chunk;
          }
        },
      };

      (mockOpenAIClient.chat.completions.create as jest.Mock).mockResolvedValue(mockStream as any);

      const messages: UnifiedMessage[] = [
        { role: 'user', content: 'ä½ å¥½' },
      ];

      const chunks: UnifiedChunk[] = [];
      for await (const chunk of adapter.chatCompletionStream({ messages })) {
        chunks.push(chunk);
      }

      expect(chunks).toHaveLength(2);
      expect(chunks[0]?.choices?.[0]?.delta?.content).toBe('ä½ å¥½');
      expect(chunks[1]?.choices?.[0]?.delta?.content).toBe('ï¼');
    });

    it('åº”è¯¥å¤„ç†æµå¼APIé”™è¯¯', async () => {
      (mockOpenAIClient.chat.completions.create as jest.Mock).mockRejectedValue(new Error('æµå¼APIé”™è¯¯'));

      const messages: UnifiedMessage[] = [
        { role: 'user', content: 'æµ‹è¯•' },
      ];

      const streamGenerator = adapter.chatCompletionStream({ messages });
      
      await expect(async () => {
        for await (const chunk of streamGenerator) {
          console.log(chunk);
        }
      }).rejects.toThrow('æµå¼APIé”™è¯¯');
    });
  });

  describe('chatCompletionWithTools', () => {
    it('åº”è¯¥è°ƒç”¨chatCompletionæ–¹æ³•å¤„ç†å·¥å…·', async () => {
      const mockResponse = {
        id: 'chatcmpl-123',
        object: 'chat.completion',
        created: 1677652288,
        model: 'gpt-3.5-turbo',
        choices: [{
          index: 0,
          message: {
            role: 'assistant',
            content: 'å·²è°ƒç”¨å·¥å…·',
          },
          finish_reason: 'stop',
        }],
      };

      (mockOpenAIClient.chat.completions.create as jest.Mock).mockResolvedValue(mockResponse as any);

      const messages: UnifiedMessage[] = [
        { role: 'user', content: 'ä½¿ç”¨å·¥å…·' },
      ];

      const tools: UnifiedTool[] = [{
        type: 'function',
        function: {
          name: 'test_tool',
          description: 'æµ‹è¯•å·¥å…·',
          parameters: { type: 'object', properties: {} },
        },
      }];

      const result = await adapter.chatCompletionWithTools(messages, tools);

      expect(mockOpenAIClient.chat.completions.create).toHaveBeenCalledWith({
        model: 'gpt-3.5-turbo',
        messages: [{ role: 'user', content: 'ä½¿ç”¨å·¥å…·' }],
        max_tokens: 1000,
        temperature: 0.7,
        tools: [{
          type: 'function',
          function: {
            name: 'test_tool',
            description: 'æµ‹è¯•å·¥å…·',
            parameters: { type: 'object', properties: {} },
          },
        }],
        tool_choice: 'auto',
        stream: false,
      });

      expect(result.choices[0]?.message?.content).toBe('å·²è°ƒç”¨å·¥å…·');
    });
  });

  describe('getAvailableTools', () => {
    it('åº”è¯¥è¿”å›ç©ºæ•°ç»„', () => {
      const tools = adapter.getAvailableTools();
      expect(tools).toEqual([]);
    });
  });

  describe('validateConfig', () => {
    it('åº”è¯¥éªŒè¯æœ‰æ•ˆé…ç½®', () => {
      expect(adapter.validateConfig()).toBe(true);
    });

    it('åº”è¯¥æ‹’ç»ç¼ºå°‘apiKeyçš„é…ç½®', () => {
      const invalidConfig = { ...mockConfig, apiKey: '' };
      const invalidAdapter = new OpenAIAdapter(invalidConfig);
      expect(invalidAdapter.validateConfig()).toBe(false);
    });

    it('åº”è¯¥æ‹’ç»ç¼ºå°‘modelçš„é…ç½®', () => {
      const invalidConfig = { ...mockConfig, model: '' };
      const invalidAdapter = new OpenAIAdapter(invalidConfig);
      expect(invalidAdapter.validateConfig()).toBe(false);
    });
  });

  describe('testConnection', () => {
    it('åº”è¯¥æˆåŠŸæµ‹è¯•è¿æ¥', async () => {
      (mockOpenAIClient.chat.completions.create as jest.Mock).mockResolvedValue({} as any);

      const result = await adapter.testConnection();

      expect(result).toBe(true);
      expect(mockOpenAIClient.chat.completions.create).toHaveBeenCalledWith({
        model: 'gpt-3.5-turbo',
        messages: [{ role: 'user', content: 'test' }],
        max_tokens: 1,
      });
    });

    it('åº”è¯¥å¤„ç†è¿æ¥å¤±è´¥', async () => {
      (mockOpenAIClient.chat.completions.create as jest.Mock).mockRejectedValue(new Error('è¿æ¥å¤±è´¥'));

      const result = await adapter.testConnection();

      expect(result).toBe(false);
    });
  });

  describe('getModelInfo', () => {
    it('åº”è¯¥è¿”å›æ¨¡å‹ä¿¡æ¯', async () => {
      const modelInfo = await adapter.getModelInfo();

      expect(modelInfo).toEqual({
        id: 'gpt-3.5-turbo',
        name: 'gpt-3.5-turbo',
        description: 'OpenAI gpt-3.5-turbo model',
        maxTokens: 1000,
        supportsFunctions: true,
        supportsStreaming: true,
      });
    });
  });

  describe('ç§æœ‰æ–¹æ³•æµ‹è¯•', () => {
    describe('convertToOpenAIMessages', () => {
      it('åº”è¯¥è½¬æ¢åŸºæœ¬æ¶ˆæ¯', () => {
        const messages: UnifiedMessage[] = [
          { role: 'user', content: 'ç”¨æˆ·æ¶ˆæ¯' },
          { role: 'assistant', content: 'åŠ©æ‰‹å›å¤' },
        ];

        const result = (adapter as any).convertToOpenAIMessages(messages);

        expect(result).toEqual([
          { role: 'user', content: 'ç”¨æˆ·æ¶ˆæ¯' },
          { role: 'assistant', content: 'åŠ©æ‰‹å›å¤' },
        ]);
      });

      it('åº”è¯¥è½¬æ¢å·¥å…·æ¶ˆæ¯', () => {
        const messages: UnifiedMessage[] = [
          {
            role: 'tool',
            content: 'å·¥å…·ç»“æœ',
            toolCallId: 'call_123',
          },
        ];

        const result = (adapter as any).convertToOpenAIMessages(messages);

        expect(result).toEqual([
          {
            role: 'tool',
            content: 'å·¥å…·ç»“æœ',
            tool_call_id: 'call_123',
          },
        ]);
      });

      it('åº”è¯¥è½¬æ¢å¸¦å·¥å…·è°ƒç”¨çš„æ¶ˆæ¯', () => {
        const messages: UnifiedMessage[] = [
          {
            role: 'assistant',
            content: '',
            toolCalls: [{
              id: 'call_123',
              type: 'function',
              function: {
                name: 'get_weather',
                arguments: '{"location": "åŒ—äº¬"}',
              },
            }],
          },
        ];

        const result = (adapter as any).convertToOpenAIMessages(messages);

        expect(result[0].tool_calls).toEqual([{
          id: 'call_123',
          type: 'function',
          function: {
            name: 'get_weather',
            arguments: '{"location": "åŒ—äº¬"}',
          },
        }]);
      });
    });

    describe('convertToOpenAITools', () => {
      it('åº”è¯¥è½¬æ¢å·¥å…·å®šä¹‰', () => {
        const tools: UnifiedTool[] = [{
          type: 'function',
          function: {
            name: 'test_function',
            description: 'æµ‹è¯•å‡½æ•°',
            parameters: {
              type: 'object',
              properties: {
                param1: { type: 'string' },
              },
            },
          },
        }];

        const result = (adapter as any).convertToOpenAITools(tools);

        expect(result).toEqual([{
          type: 'function',
          function: {
            name: 'test_function',
            description: 'æµ‹è¯•å‡½æ•°',
            parameters: {
              type: 'object',
              properties: {
                param1: { type: 'string' },
              },
            },
          },
        }]);
      });
    });

    describe('convertToOpenAIToolChoice', () => {
      it('åº”è¯¥å¤„ç†å­—ç¬¦ä¸²å·¥å…·é€‰æ‹©', () => {
        const result = (adapter as any).convertToOpenAIToolChoice('auto');
        expect(result).toBe('auto');
      });

      it('åº”è¯¥å¤„ç†å¯¹è±¡å·¥å…·é€‰æ‹©', () => {
        const toolChoice = {
          function: { name: 'specific_function' },
        };

        const result = (adapter as any).convertToOpenAIToolChoice(toolChoice);

        expect(result).toEqual({
          type: 'function',
          function: { name: 'specific_function' },
        });
      });
    });

    describe('convertFromOpenAIResponse', () => {
      it('åº”è¯¥è½¬æ¢OpenAIå“åº”', () => {
        const openaiResponse = {
          id: 'chatcmpl-123',
          object: 'chat.completion',
          created: 1677652288,
          model: 'gpt-3.5-turbo',
          choices: [{
            index: 0,
            message: {
              role: 'assistant',
              content: 'æµ‹è¯•å›å¤',
            },
            finish_reason: 'stop',
          }],
          usage: {
            prompt_tokens: 10,
            completion_tokens: 20,
            total_tokens: 30,
          },
        };

        const result = (adapter as any).convertFromOpenAIResponse(openaiResponse);

        expect(result).toEqual({
          id: 'chatcmpl-123',
          object: 'chat.completion',
          created: 1677652288,
          model: 'gpt-3.5-turbo',
          choices: [{
            index: 0,
            message: {
              role: 'assistant',
              content: 'æµ‹è¯•å›å¤',
            },
            finishReason: 'stop',
          }],
          usage: {
            promptTokens: 10,
            completionTokens: 20,
            totalTokens: 30,
          },
        });
      });

      it('åº”è¯¥å¤„ç†æ²¡æœ‰usageçš„å“åº”', () => {
        const openaiResponse = {
          id: 'chatcmpl-123',
          object: 'chat.completion',
          created: 1677652288,
          model: 'gpt-3.5-turbo',
          choices: [{
            index: 0,
            message: {
              role: 'assistant',
              content: 'æµ‹è¯•å›å¤',
            },
            finish_reason: 'stop',
          }],
        };

        const result = (adapter as any).convertFromOpenAIResponse(openaiResponse);

        expect(result.usage).toBeUndefined();
      });
    });

    describe('convertFromOpenAIChunk', () => {
      it('åº”è¯¥è½¬æ¢OpenAIæµå¼å—', () => {
        const openaiChunk = {
          id: 'chatcmpl-123',
          object: 'chat.completion.chunk',
          created: 1677652288,
          model: 'gpt-3.5-turbo',
          choices: [{
            index: 0,
            delta: {
              role: 'assistant',
              content: 'æµå¼å†…å®¹',
            },
            finish_reason: null,
          }],
        };

        const result = (adapter as any).convertFromOpenAIChunk(openaiChunk);

        expect(result).toEqual({
          id: 'chatcmpl-123',
          object: 'chat.completion.chunk',
          created: 1677652288,
          model: 'gpt-3.5-turbo',
          choices: [{
            index: 0,
            delta: {
              role: 'assistant',
              content: 'æµå¼å†…å®¹',
            },
            finishReason: null,
          }],
        });
      });
    });

    describe('convertFromOpenAIMessage', () => {
      it('åº”è¯¥è½¬æ¢åŸºæœ¬æ¶ˆæ¯', () => {
        const openaiMessage = {
          role: 'assistant',
          content: 'åŠ©æ‰‹æ¶ˆæ¯',
        };

        const result = (adapter as any).convertFromOpenAIMessage(openaiMessage);

        expect(result).toEqual({
          role: 'assistant',
          content: 'åŠ©æ‰‹æ¶ˆæ¯',
        });
      });

      it('åº”è¯¥è½¬æ¢å¸¦å·¥å…·è°ƒç”¨çš„æ¶ˆæ¯', () => {
        const openaiMessage = {
          role: 'assistant',
          content: null,
          tool_calls: [{
            id: 'call_123',
            type: 'function',
            function: {
              name: 'get_weather',
              arguments: '{"location": "åŒ—äº¬"}',
            },
          }],
        };

        const result = (adapter as any).convertFromOpenAIMessage(openaiMessage);

        expect(result).toEqual({
          role: 'assistant',
          content: '',
          toolCalls: [{
            id: 'call_123',
            type: 'function',
            function: {
              name: 'get_weather',
              arguments: '{"location": "åŒ—äº¬"}',
            },
          }],
        });
      });

      it('åº”è¯¥å¤„ç†ç©ºæ¶ˆæ¯', () => {
        const openaiMessage = {};

        const result = (adapter as any).convertFromOpenAIMessage(openaiMessage);

        expect(result).toEqual({
          role: 'assistant',
          content: '',
        });
      });
    });
  });

  describe('é”™è¯¯å¤„ç†', () => {
    it('åº”è¯¥å¤„ç†ç½‘ç»œé”™è¯¯', async () => {
      (mockOpenAIClient.chat.completions.create as jest.Mock).mockRejectedValue(new Error('ç½‘ç»œè¿æ¥å¤±è´¥'));

      const messages: UnifiedMessage[] = [
        { role: 'user', content: 'æµ‹è¯•' },
      ];

      await expect(adapter.chatCompletion({ messages })).rejects.toThrow('ç½‘ç»œè¿æ¥å¤±è´¥');
    });

    it('åº”è¯¥å¤„ç†è®¤è¯é”™è¯¯', async () => {
      const authError = new Error('è®¤è¯å¤±è´¥');
      (authError as any).status = 401;
      (mockOpenAIClient.chat.completions.create as jest.Mock).mockRejectedValue(authError);

      const messages: UnifiedMessage[] = [
        { role: 'user', content: 'æµ‹è¯•' },
      ];

      await expect(adapter.chatCompletion({ messages })).rejects.toThrow('è®¤è¯å¤±è´¥');
    });
  });
});